{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten #, Reshape\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "\n",
    "%run plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "str0 = 'ts_L60_Z12_A500_DX50_bias5_N10000.dat'\n",
    "fnamex='DATA/x_'+str0\n",
    "fnamey='DATA/y_'+str0\n",
    "\n",
    "x = np.loadtxt(fnamex, delimiter=\" \",dtype=float)\n",
    "N,L = len(x), len(x[0])\n",
    "\n",
    "Show_data(x,L,\"original data\")\n",
    "\n",
    "categ = np.loadtxt(fnamey, dtype=int)\n",
    "n_class = 3    # y.argmax() - y.argmin() +1\n",
    "print('data: ',N)\n",
    "\n",
    "y = np.zeros((N,n_class))\n",
    "for i in range(N):\n",
    "    y[i][categ[i]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale data, split train/val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  FIRST PASSAGE:  DO NOT DO THIS --> FAILURE \n",
    "#\n",
    "#remove average value of each sample from its values\n",
    "xm = x.mean(axis=1)\n",
    "for i in range(N):\n",
    "    x[i] = x[i]-xm[i]\n",
    "\n",
    "#\n",
    "#  SECOND PASSAGE:  DO NOT DO THIS --> ALSO FAILURE \n",
    "#\n",
    "#rescale (crude version, variance should be used)\n",
    "x = x/400\n",
    "    \n",
    "Show_data(x,L,\"rescaled data\")\n",
    "\n",
    "perc_train=0.8\n",
    "N_train = int(perc_train*N)\n",
    "x_train = x[:N_train]\n",
    "y_train = y[:N_train]\n",
    "x_val = x[N_train:]\n",
    "y_val = y[N_train:]\n",
    "N_val = len(x_val)\n",
    "print('N_train=',N_train,'  N_val=',N_val,'  L=',L,'  n_class=',n_class)\n",
    "\n",
    "#x_train=x_train.astype(\"float32\")\n",
    "#y_train=y_train.astype(\"float32\")\n",
    "#x_val=x_val.astype(\"float32\")\n",
    "#y_val=y_val.astype(\"float32\")\n",
    "\n",
    "# Keras wants an additional dimension with a 1 at the end\n",
    "x_train = x_train.reshape(x_train.shape[0], L, 1)\n",
    "x_val =  x_val.reshape(x_val.shape[0], L, 1)\n",
    "input_shape = (L, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... LESSON ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_weights(model,l=0,label=\"model\"):\n",
    "    c=['r','y','c','b','m']\n",
    "    m=['o','s','D','<','>']\n",
    "    ms=10\n",
    "    \n",
    "    w = model.layers[l].get_weights()[0]\n",
    "    wT=w.T\n",
    "    M=len(wT)\n",
    "    b = model.layers[l].get_weights()[1]\n",
    "    \n",
    "    fig,AX=plt.subplots(1,2,figsize=(12,4.4))\n",
    "    ax=AX[0]\n",
    "    ax.axhline(0, c=\"k\")\n",
    "    ax.plot((0,))\n",
    "    for i in range(M):\n",
    "        ax.plot(wT[i][0],\"-\",c=c[i],marker=m[i],label=str(i),markersize=ms)\n",
    "    ax.set_title(label+': filters of layer '+str(l))\n",
    "    ax.set_xlabel('index')\n",
    "    ax=AX[1]\n",
    "    ax.axhline(0, c=\"k\")\n",
    "    for i in range(M):\n",
    "        ax.plot((i),(b[i]),c=c[i],marker=m[i],label=\"filter \"+str(i),markersize=ms)\n",
    "    ax.set_title(label+': bias of layer '+str(l))\n",
    "    ax.set_xlabel('filter nr')\n",
    "    ax.set_xticks(np.arange(5))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "Show_weights(model,0)\n",
    "Show_weights(model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...LESSON ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_history(fit):\n",
    "    fig,AX=plt.subplots(1,2,figsize=(12,5.))\n",
    "    ax=AX[0]\n",
    "    ax.plot(fit.history['accuracy'],\"b\",label=\"train\")\n",
    "    ax.plot(fit.history['val_accuracy'],\"r--\",label=\"valid.\")\n",
    "    ax.plot((0,EPOCHS),(1/3,1/3),\":\",c=\"gray\",label=\"random choice\")\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend()\n",
    "    ax=AX[1]\n",
    "    ax.plot(fit.history['loss'],\"b\",label=\"train\")\n",
    "    ax.plot(fit.history['val_loss'],\"r--\",label=\"valid.\")\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_ylim([0, 1.05*np.max(fit.history['loss'])])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "Show_history(fit)\n",
    "Show_weights(model,0)\n",
    "Show_weights(model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...LESSON ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_history(fit)\n",
    "Show_history(fit2)\n",
    "Show_weights(model2,0,label=\"model2\")\n",
    "Show_weights(model2,2,label=\"model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn \n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "LABELS = [\"absent\",\"positive\",\"negative\"]\n",
    "cmap=\"GnBu\"\n",
    "\n",
    "def show_confusion_matrix(validations, predictions):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    seaborn.heatmap(matrix,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                cmap=cmap)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "y_pred_val = model.predict(x_val)\n",
    "# Take the class with the highest probability from the val predictions\n",
    "max_y_pred_val = np.argmax(y_pred_val, axis=1)\n",
    "max_y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "show_confusion_matrix(max_y_val, max_y_pred_val)\n",
    "\n",
    "#print(classification_report(max_y_val, max_y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
